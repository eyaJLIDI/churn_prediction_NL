{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4+ewJUZE020tyDhzEFpIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaJLIDI/churn_prediction_NL/blob/main/preparation_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enriPXg_e4HQ",
        "outputId": "5969bbe1-8b1b-4952-b38d-7c16c68b6715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "import sklearn \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "H2BbVn9wsw-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelisation(data):\n",
        "  spark =  SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"NL+ churn prediction\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "  df = spark.createDataFrame(data)\n",
        "  display(df)\n",
        "  df = df.withColumn(\"evol_trajet\",df.evol_trajet.cast('double'))\n",
        "  categoricalColumns = ['PROFIL_IMPAYE', 'SEXE', 'CLT_SOLLICITATION_IND', 'PROFIL_TARIFAIRE17', 'MEDIA', 'CLT_SOLLICITATION_IDFM_IND', 'TYPE_RESIL', 'ACTEUR_RESIL', 'profil_tarifaire46']\n",
        "  stages = []\n",
        "\n",
        "  for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index', handleInvalid = 'error')\n",
        "    #stringIndexer = stringIndexer.setHandleInvalid(\"error\")\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]\n",
        "\n",
        "  label_stringIdx = StringIndexer(inputCol = 'CHURN_shift', outputCol = 'label')\n",
        "  stages += [label_stringIdx]\n",
        "  numericCols = ['AGE', 'NOMBRE_CONTRAT_IR_SCO','NOMBRE_CONTRAT_IR_ETU','NOMBRE_CONTRAT_NA','NOMBRE_CONTRAT_NMS','NOMBRE_GRAT','NOMBRE_SOL','NOMBRE_AME','ADR_CODE_POSTAL','PORTEUR_PAYEUR','CLT_SEL_IND','MONTANT23','ANCIENNETE_NLP',\n",
        " 'CONTRATS_PRECEDENTS','NOMBRE_DEPT_RESIDENCE_MOIS','DT_MEAN','ECART_TYPE','VOL_INTERACTION','VOL_EVT','performance','VOL_EVT_SIMPLE','VOL_INTERACTION_SIMPLE','DT_MEAN_SIMPLE','VOL_EVT_STANDARD','VOL_INTERACTION_STANDARD','DT_MEAN_STANDARD','VOL_EVT_COMPLIQUE',\n",
        " 'VOL_INTERACTION_COMPLIQUE','DT_MEAN_COMPLIQUE','VOL_EVT_BLOQ','VOL_INTERACTION_BLOQ','DT_MEAN_BLOQ','nombre','montant48','montant_offert','evol_trajet']\n",
        "  assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
        "  assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "  stages += [assembler]\n",
        "\n",
        "  pipeline = Pipeline(stages = stages)\n",
        "  pipelineModel = pipeline.fit(df)\n",
        "  df = pipelineModel.transform(df)\n",
        "  selectedCols = ['label', 'features']\n",
        "  df = df.select(selectedCols)\n",
        "  df.printSchema()\n",
        "  classification_data = df.select('features', 'label')\n",
        "  classification_data.show()\n",
        "  train, test = classification_data.randomSplit([0.7, 0.3])\n",
        "  dtc = DecisionTreeClassifier(labelCol=\"label\")\n",
        "  dtc = dtc.fit(train)\n",
        "  pred = dtc.transform(test)\n",
        "  pred.show(10)\n",
        "  evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "  acc = evaluator.evaluate(pred)\n",
        " \n",
        "  print(\"Prediction Accuracy: \", acc)\n",
        " \n",
        "  y_pred=pred.select(\"prediction\").collect()\n",
        "  y_orig=pred.select(\"label\").collect()\n",
        "\n",
        "  print(classification_report(y_orig, y_pred))\n",
        "\n",
        "  print('Random forest classifier :')\n",
        "  rfc = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "  rfc = rfc.fit(train)\n",
        "\n",
        "  pred = rfc.transform(test)\n",
        "  pred.show(3)\n",
        "  evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "  acc = evaluator.evaluate(pred)\n",
        " \n",
        "  print(\"Prediction Accuracy: \", acc)\n",
        " \n",
        "  y_pred=pred.select(\"prediction\").collect()\n",
        "  y_orig=pred.select(\"label\").collect()\n",
        "\n",
        "  cm = confusion_matrix(y_orig, y_pred)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "2fIfkY1m2H__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9PLfJM-2P1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}